{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "from transformers import MarkupLMFeatureExtractor, MarkupLMProcessor, MarkupLMForTokenClassification\n",
    "from bs4 import BeautifulSoup\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "allowed_labels = [\"title\", \"short_text\", \"date\", \"time\", \"tag\", \"short_title\", \"author\"]\n",
    "\n",
    "label2id = {label: idx+1 for idx, label in enumerate(allowed_labels)}\n",
    "label2id[\"OTHER\"] = 0\n",
    "\n",
    "id2label = {idx+1: label for idx, label in enumerate(allowed_labels)}\n",
    "id2label[0] = \"OTHER\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_folder(folder_path : str):\n",
    "    '''\n",
    "        This function loading all json files from folder.\n",
    "        Each file contains dict with labels and its values.\n",
    "        Each file must contains \"html\" label with its html code. \n",
    "        Each file must contains \"xpaths\" label with its labeled xpaths list. \n",
    "        \n",
    "    '''\n",
    "    extractor = MarkupLMFeatureExtractor()\n",
    "    \n",
    "    folder_path = os.path.abspath(folder_path)\n",
    "    files_path = glob(os.path.join(folder_path, \"*.json\"))\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for file_path in tqdm(files_path):\n",
    "        # print(file_path)\n",
    "        with open(file_path) as file:\n",
    "            info = json.load(file)\n",
    "            \n",
    "        html = info[\"html\"]\n",
    "        labeled_xpaths = info[\"labeled_xpaths\"]\n",
    "\n",
    "        encoding = extractor(html)\n",
    "            \n",
    "        \n",
    "        labels = []\n",
    "        for xpath in encoding[\"xpaths\"][0]:\n",
    "            if xpath in labeled_xpaths:\n",
    "                labels.append(label2id[labeled_xpaths[xpath]])\n",
    "            else:\n",
    "                labels.append(0)\n",
    "        \n",
    "        if (len([_ for _ in labels if _ !=  0]) == 0):\n",
    "            raise Exception(\"No labeled data found\")\n",
    "\n",
    "        \n",
    "        labels = [labels]\n",
    "        # print(len(encoding['nodes'][0]), len(encoding['xpaths'][0]), len(labels[0]))\n",
    "        data.append({'nodes': encoding['nodes'],\n",
    "                     'xpaths': encoding['xpaths'],\n",
    "                     'node_labels': labels,\n",
    "                     'html': html})\n",
    "        \n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2599 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2599/2599 [01:57<00:00, 22.19it/s]\n",
      "100%|██████████| 867/867 [00:36<00:00, 23.58it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = load_from_folder(\"test_dataset/train_part\")\n",
    "valid_data = load_from_folder(\"test_dataset/test_part\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size :  2599\n",
      "Test size :  867\n",
      "Train proportion :  0.7498557414887478\n"
     ]
    }
   ],
   "source": [
    "print(\"Train size : \", len(train_data))\n",
    "print(\"Test size : \", len(valid_data))\n",
    "print(\"Train proportion : \", len(train_data) / (len(valid_data) + len(train_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Radio title\n",
      "Special projects title\n",
      "News title\n",
      "Power tag\n",
      "Policy tag\n",
      "Mayor of Moscow tag\n",
      "Society tag\n",
      "Policy tag\n",
      "Accidents tag\n",
      "regions tag\n",
      "Accidents tag\n",
      "Mayor of Moscow tag\n",
      "City tag\n",
      "Power tag\n",
      "Policy tag\n",
      "Power tag\n",
      "Policy tag\n",
      "Economics tag\n",
      "Policy tag\n",
      "Accidents tag\n",
      "regions tag\n",
      "Accidents tag\n",
      "fire tag\n",
      "Mayor of Moscow tag\n",
      "transport tag\n",
      "Policy tag\n",
      "Accidents tag\n",
      "Power tag\n",
      "sports tag\n",
      "Accidents tag\n",
      "Abroad tag\n",
      "transport tag\n",
      "Accidents tag\n",
      "Power tag\n",
      "Policy tag\n",
      "Accidents tag\n",
      "regions tag\n",
      "Culture tag\n",
      "Accidents tag\n",
      "Policy tag\n",
      "Environment tag\n",
      "Culture tag\n",
      "Power tag\n",
      "Policy tag\n",
      "Accidents tag\n",
      "Power tag\n",
      "Policy tag\n",
      "Science tag\n",
      "Putin thanked Alexander Lukashenko for coming to St. Petersburg. title\n",
      "19:51 date\n",
      "Power tag\n",
      "Policy tag\n",
      "CEC will consider registering Putin in presidential elections on 29 January title\n",
      "19:24 date\n",
      "Policy tag\n",
      "Putin promised to inform Lukashenko of what was happening in the SVO area. title\n",
      "18:48 date\n",
      "Power tag\n",
      "Policy tag\n",
      "Putin stated that the RF and Beloroussi relations were developing very vigorously. title\n",
      "18:44 date\n",
      "Power tag\n",
      "Policy tag\n",
      "Economics tag\n",
      "Zaharova called a monstrous execution of a prisoner in the U.S. pure nitrogen title\n",
      "18:24 date\n",
      "Policy tag\n",
      "The army of the Russian Federation told me how the VSA left the wounded when the field hospital was taken to the rear. title\n",
      "17:41 date\n",
      "Policy tag\n",
      "Putin noted the contribution of the Navy ' s military personnel to the preservation of Russia ' s fleet history. title\n",
      "16:47 date\n",
      "Power tag\n",
      "Policy tag\n",
      "Rusophobia in the West will last decades, but common sense prevails - Peskov. title\n",
      "15:53 date\n",
      "Power tag\n",
      "Policy tag\n",
      "Putin started the winter station at the Antarctic. title\n",
      "15:26 date\n",
      "Power tag\n",
      "Policy tag\n",
      "Science tag\n",
      "The memory of the lening of the Leningrads gives true values to young people - Patirusev title\n",
      "11:30. date\n",
      "Policy tag\n",
      "Peskov told me how he managed to combine his father and work. title\n",
      "11:07 date\n",
      "Power tag\n",
      "Policy tag\n",
      "MFA warned the West of the effects of the confiscation of Russian assets title\n",
      "08:58 date\n",
      "Policy tag\n",
      "The head of the Navy of Ukraine expressed the wish to accept the ships written off in Britain. title\n",
      "07:54 date\n",
      "Policy tag\n",
      "Putin and Lukashenko will approve new integration programmes for 2024-2026 - MFA title\n",
      "07:27 date\n",
      "Policy tag\n",
      "The DPRK launched several cruise missiles towards the Japan Sea title\n",
      "05:26 date\n",
      "Policy tag\n",
      "Abroad tag\n",
      "The world can be seen as the beginning of the third world war - the media title\n",
      "04:35 date\n",
      "Policy tag\n",
      "The Green Formula has been hindered by the proposals of the CPD, Brazil and Africa for Ukraine, the MYFF title\n",
      "02:01 date\n",
      "Policy tag\n",
      "A series of explosions took place in the city of Zaporozje under the control of Kyiv. title\n",
      "00:59 date\n",
      "Policy tag\n",
      "Belarus-Russian integration does not threaten the sovereignty of Belarus-Mesents title\n",
      "21:19 date\n",
      "Policy tag\n",
      "The French Farmers ' Union announced its intention to organize a full blockade of Paris. title\n",
      "21:15 date\n",
      "Policy tag\n",
      "video video tag\n",
      "Karina Ilina tag\n",
      "Kabmin transferred part of the Azona sea to the Crimea for the Defence of the RF title\n",
      "20:19 date\n",
      "Policy tag\n",
      "Minsk and Moscow are open to any friendly steps to meet - Lucashenko title\n",
      "19:53 date\n",
      "Policy tag\n",
      "Byden said he was going to close the border for illegal refugees from Mexico. title\n",
      "19:30 date\n",
      "Policy tag\n",
      "video video tag\n",
      "Karina Ilina tag\n",
      "The United States is counting on Bayden and C talking in the coming months - the White House. title\n",
      "19:28 date\n",
      "Policy tag\n",
      "The victims of the Hitler genocide in the USSR were 15 to 16 million people, the Medo title\n",
      "19:22 date\n",
      "Power tag\n",
      "Policy tag\n",
      "Affix the file. title\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for node, label in zip(valid_data[idx]['nodes'][0], valid_data[idx]['node_labels'][0]):\n",
    "  if id2label[label] != 'OTHER':\n",
    "    print(node, id2label[label])\n",
    "  # print(node, id2label[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Инициалиация датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkupLMDataset(Dataset):\n",
    "    \"\"\"Dataset for token classification with MarkupLM.\"\"\"\n",
    "\n",
    "    def __init__(self, data, processor=None):\n",
    "        self.data = data\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # first, get nodes, xpaths and node labels\n",
    "        item = self.data[idx]\n",
    "        nodes, xpaths, node_labels = item['nodes'], item['xpaths'], item['node_labels']\n",
    "\n",
    "        # provide to processor\n",
    "        encoding = self.processor(nodes=nodes, xpaths=xpaths, node_labels=node_labels, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "        # remove batch dimension\n",
    "        encoding = {k: v.squeeze() for k, v in encoding.items()}\n",
    "\n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = MarkupLMProcessor.from_pretrained(\"microsoft/markuplm-base\", truncation = True)\n",
    "processor.parse_html = False\n",
    "\n",
    "train_set = MarkupLMDataset(data=train_data, processor=processor)\n",
    "valid_set = MarkupLMDataset(data=valid_data, processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([512])\n",
      "token_type_ids torch.Size([512])\n",
      "attention_mask torch.Size([512])\n",
      "xpath_tags_seq torch.Size([512, 50])\n",
      "xpath_subs_seq torch.Size([512, 50])\n",
      "labels torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "example = valid_set[0]\n",
    "for k,v in example.items():\n",
    "  print(k,v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>Recent news in Moscow - Moscow 24 - M24.RUMoscow 24TVRadioSpecial projectsNewsHistoryPhoto galleryVideoInfographyAudioProgrammesReverse communicationContactsAdvertisementPolicySocietyEconomyWorldSportCasesCultureShaw businessTechnologyScienceTransportCitySecurityEnvironmentHistoryExclusionsDevelopmentsCoronaurus COVID-19TourismRegionsMayor of MoscowWeb search formAbroadMetrosecurityMoscow 24TVRadioExclusionsSpecial projectsWeb search formSpecial operationsMoscow onlineNewsHistoryPhoto galleryVideoInfographyAudioProgrammesPolicySocietyEconomyWorldSportCasesCultureReverse communicationContactsAdvertisementTelegramVkontakteGradesYoutubeRutubeICQViberTiktokNewsNewsMayor of MoscowSobyanin: 49 new Moscow Longevity Centres opened last year19:51Putin thanked Alexander Lukashenko for coming to St. Petersburg.PowerPolicy19:43Sobyanin: 49 new Moscow Longevity Centres opened last yearMayor of MoscowSociety19:24CEC will consider registering Putin in presidential elections on 29 JanuaryPolicy19:19The workers suffered as a result of the attack of the Drone Kakadze in the Belgorod regionAccidentsregions19:09The head of the SCF has taken over the investigation into the case of the beating of journalists by the Izvestya.Accidents19:07Sobyanin: more than 1 million lighters are lighted at evenings in MoscowMayor of MoscowCity18:48Putin promised to inform Lukashenko of what was happening in the SVO area.PowerPolicy18:44Putin stated that the RF and Beloroussi relations were developing very vigorously.PowerPolicyEconomics18:24Zaharova called a monstrous execution of a prisoner in the U.S. pure nitrogenPolicy18:22A woman was injured because of the explosion of an explosive object from a U.S. drone in DonetskAccidentsregions18:03The Department of Public Prosecutions monitors the progress of the fire check in Theatre of the satire.Accidentsfire17:55The sale of green bonds resulted in the purchase for Moscow of 51 electric beans - SobyaninMayor of Moscowtransport17:41The army of the Russian Federation told me how the VSA left the wounded when the field hospital was taken to the rear.Policy17:30Russian PSBs have been hit by a Ukrainian drone over the Belgorod Region - MS FAccidents17:</s>'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.decode(example['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recent 0\n",
      "Moscow 0\n",
      "TV 0\n",
      "Radio 1\n",
      "Special 1\n",
      "News 0\n",
      "History 0\n",
      "Photo 0\n",
      "Video 0\n",
      "Inf 0\n",
      "Audio 0\n",
      "Program 0\n",
      "R 0\n",
      "Cont 0\n",
      "Advertisement 0\n",
      "Policy 0\n",
      "Soc 0\n",
      "Econom 0\n",
      "World 0\n",
      "Sport 0\n",
      "C 0\n",
      "C 0\n",
      "Sh 0\n",
      "Technology 0\n",
      "Science 0\n",
      "Trans 0\n",
      "City 0\n",
      "Security 0\n",
      "Environment 0\n",
      "History 0\n",
      "Ex 0\n",
      "Develop 0\n",
      "Cor 0\n",
      "Tour 0\n",
      "Reg 0\n",
      "Mayor 0\n",
      "Web 0\n",
      "Ab 0\n",
      "Metro 0\n",
      "security 0\n",
      "Moscow 0\n",
      "TV 0\n",
      "Radio 0\n",
      "Ex 0\n",
      "Special 0\n",
      "Web 0\n",
      "Special 0\n",
      "Moscow 0\n",
      "News 0\n",
      "History 0\n",
      "Photo 0\n",
      "Video 0\n",
      "Inf 0\n",
      "Audio 0\n",
      "Program 0\n",
      "Policy 0\n",
      "Soc 0\n",
      "Econom 0\n",
      "World 0\n",
      "Sport 0\n",
      "C 0\n",
      "C 0\n",
      "R 0\n",
      "Cont 0\n",
      "Advertisement 0\n",
      "Te 0\n",
      "V 0\n",
      "Gr 0\n",
      "Y 0\n",
      "R 0\n",
      "IC 0\n",
      "V 0\n",
      "T 0\n",
      "News 1\n",
      "News 0\n",
      "Mayor 0\n",
      "S 0\n",
      "19 0\n",
      "Putin 0\n",
      "Power 5\n",
      "Policy 5\n",
      "19 0\n",
      "S 0\n",
      "Mayor 5\n",
      "Soc 5\n",
      "19 0\n",
      "C 0\n",
      "Policy 5\n",
      "19 0\n",
      "The 0\n",
      "Acc 5\n",
      "reg 5\n",
      "19 0\n",
      "The 0\n",
      "Acc 5\n",
      "19 0\n",
      "S 0\n",
      "Mayor 5\n",
      "City 5\n",
      "18 0\n",
      "Putin 0\n",
      "Power 5\n",
      "Policy 5\n",
      "18 0\n",
      "Putin 0\n",
      "Power 5\n",
      "Policy 5\n",
      "Econom 5\n",
      "18 0\n",
      "Z 0\n",
      "Policy 5\n",
      "18 0\n",
      "A 0\n",
      "Acc 5\n",
      "reg 5\n",
      "18 0\n",
      "The 0\n",
      "Acc 5\n",
      "fire 5\n",
      "17 0\n",
      "The 0\n",
      "Mayor 5\n",
      "trans 5\n",
      "17 0\n",
      "The 0\n",
      "Policy 5\n",
      "17 0\n",
      "Russian 0\n",
      "Acc 5\n",
      "17 0\n"
     ]
    }
   ],
   "source": [
    "for id, label in zip(example['input_ids'].tolist(), example['labels'].tolist()):\n",
    "    if label != -100:\n",
    "        print(processor.decode([id]), label)\n",
    "    # if label == 1:\n",
    "    #     print(processor.decode([id]), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MarkupLMForTokenClassification were not initialized from the model checkpoint at microsoft/markuplm-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded\n"
     ]
    }
   ],
   "source": [
    "model = MarkupLMForTokenClassification.from_pretrained(\"microsoft/markuplm-base\", id2label=id2label, label2id=label2id)\n",
    "\n",
    "if os.path.exists(\"extracting_model.pth\"):\n",
    "    model.load_state_dict(torch.load(\"extracting_model.pth\"))\n",
    "    print(\"Model Loaded\")\n",
    "else:\n",
    "    print(\"Its new model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "best_metric = 0\n",
    "\n",
    "train_history = []\n",
    "test_history = []\n",
    "\n",
    "def train_model(): \n",
    "    model.train()\n",
    "\n",
    "    labels_true = []\n",
    "    labels_predicted = []\n",
    "\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        # get the inputs;\n",
    "        inputs = {k:v.to(device) for k,v in batch.items()}\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print(\"Loss:\", loss.item())\n",
    "\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "\n",
    "        labels_predicted += predictions[0].tolist()\n",
    "        labels_true += inputs[\"labels\"][0].tolist()\n",
    "\n",
    "    score = classification_report(labels_true, labels_predicted, output_dict=True, zero_division=0)['macro avg']['f1-score']\n",
    "    with open(\"out_log.txt\", \"a\") as logfile:\n",
    "        print(datetime.datetime.now())\n",
    "        print(\"Train : \\n\", score, file=logfile)\n",
    "\n",
    "    train_history.append(score)\n",
    "    with open(\"train_history.json\", \"w\") as f:\n",
    "        json.dump(train_history, f)\n",
    "\n",
    "    print(f\"Train : {score}\")\n",
    "\n",
    "\n",
    "def test_model():\n",
    "    model.eval()\n",
    "\n",
    "    global best_metric\n",
    "    labels_true = []\n",
    "    labels_predicted = []\n",
    "\n",
    "    for batch in tqdm(valid_dataloader):\n",
    "        # get the inputs;\n",
    "        inputs = {k:v.to(device) for k,v in batch.items()}\n",
    "\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "\n",
    "        labels_predicted += predictions[0].tolist()\n",
    "        labels_true += inputs[\"labels\"][0].tolist()\n",
    "\n",
    "    score = classification_report(labels_true, labels_predicted, output_dict=True, zero_division=0)\n",
    "    with open(\"out_log.txt\", \"a\") as logfile:\n",
    "        print(datetime.datetime.now())\n",
    "        print(\"Test : \\n\", score, file=logfile)\n",
    "    \n",
    "    score_f1 = score['macro avg']['f1-score']\n",
    "\n",
    "    if score_f1 > best_metric:\n",
    "        best_metric = score_f1     \n",
    "        torch.save(model.state_dict(), f\"extracting_model.pth\")\n",
    "\n",
    "    test_history.append(score_f1)\n",
    "    with open(\"test_history.json\", \"w\") as f:\n",
    "        json.dump(test_history, f)\n",
    "    print(f\"Test : {score_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "print(device)\n",
    "for epoch in range(0):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    train_model()\n",
    "    test_model()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 217/217 [00:46<00:00,  4.69it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m     labels_true \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     22\u001b[0m score \u001b[38;5;241m=\u001b[39m classification_report(labels_true, labels_predicted, output_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(allowed_labels, [score[label2id[label]] \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m allowed_labels])\n",
      "Cell \u001b[0;32mIn[36], line 23\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     20\u001b[0m     labels_true \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     22\u001b[0m score \u001b[38;5;241m=\u001b[39m classification_report(labels_true, labels_predicted, output_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(allowed_labels, [\u001b[43mscore\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel2id\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m allowed_labels])\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "\n",
    "labels_true = []\n",
    "labels_predicted = []\n",
    "\n",
    "for batch in tqdm(valid_dataloader):\n",
    "    # get the inputs;\n",
    "    inputs = {k:v.to(device) for k,v in batch.items()}\n",
    "\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    predictions = outputs.logits.argmax(dim=-1)\n",
    "\n",
    "    labels_predicted += predictions[0].tolist()\n",
    "    labels_true += inputs[\"labels\"][0].tolist()\n",
    "\n",
    "score = classification_report(labels_true, labels_predicted, output_dict=True, zero_division=0)\n",
    "\n",
    "plt.scatter(allowed_labels, [score[str(label2id[label])]['f1-score'] for label in allowed_labels])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "markup-segmentation-03k7_eFX-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

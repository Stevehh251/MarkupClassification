{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "from transformers import MarkupLMFeatureExtractor, MarkupLMProcessor, MarkupLMForTokenClassification\n",
    "from bs4 import BeautifulSoup\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "\n",
    "allowed_labels = [\"title\", \"short_text\", \"date\", \"time\", \"tag\", \"short_title\", \"author\"]\n",
    "\n",
    "label2id = {label: idx+1 for idx, label in enumerate(allowed_labels)}\n",
    "label2id[\"OTHER\"] = 0\n",
    "\n",
    "id2label = {idx+1: label for idx, label in enumerate(allowed_labels)}\n",
    "id2label[0] = \"OTHER\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_folder(folder_path : str):\n",
    "    '''\n",
    "        This function loading all json files from folder.\n",
    "        Each file contains dict with labels and its values.\n",
    "        Each file must contains \"html\" label with its html code. \n",
    "        Each file must contains \"xpaths\" label with its labeled xpaths list. \n",
    "        \n",
    "    '''\n",
    "    extractor = MarkupLMFeatureExtractor()\n",
    "    \n",
    "    folder_path = os.path.abspath(folder_path)\n",
    "    files_path = glob(os.path.join(folder_path, \"*.json\"))\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for file_path in tqdm(files_path):\n",
    "        # print(file_path)\n",
    "        with open(file_path) as file:\n",
    "            info = json.load(file)\n",
    "            \n",
    "        html = info[\"html\"]\n",
    "        labeled_xpaths = info[\"labeled_xpaths\"]\n",
    "\n",
    "        encoding = extractor(html)\n",
    "            \n",
    "        \n",
    "        labels = []\n",
    "        for xpath in encoding[\"xpaths\"][0]:\n",
    "            if xpath in labeled_xpaths:\n",
    "                labels.append(label2id[labeled_xpaths[xpath]])\n",
    "            else:\n",
    "                labels.append(0)\n",
    "\n",
    "\n",
    "        # print(len(labels))\n",
    "        # print([_ for _ in labels if _ != 0])\n",
    "        \n",
    "        if (len([_ for _ in labels if _ != 0]) == 0):\n",
    "            with open(\"bad_file.txt\", \"a\") as file:\n",
    "                print(file_path, file=file)\n",
    "\n",
    "        \n",
    "        labels = [labels]\n",
    "        # print(len(encoding['nodes'][0]), len(encoding['xpaths'][0]), len(labels[0]))\n",
    "        data.append({'nodes': encoding['nodes'],\n",
    "                     'xpaths': encoding['xpaths'],\n",
    "                     'node_labels': labels,\n",
    "                     'html': html})\n",
    "        \n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1980/1980 [04:51<00:00,  6.80it/s]\n",
      "100%|██████████| 850/850 [01:52<00:00,  7.57it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = load_from_folder(\"test_dataset/train_part\")\n",
    "valid_data = load_from_folder(\"test_dataset/test_part\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size :  1980\n",
      "Test size :  850\n",
      "Train proportion :  0.6996466431095406\n"
     ]
    }
   ],
   "source": [
    "print(\"Train size : \", len(train_data))\n",
    "print(\"Test size : \", len(valid_data))\n",
    "print(\"Train proportion : \", len(train_data) / (len(valid_data) + len(train_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В Башкирии презентовали гастрономический гид title\n",
      "16.02.2024 08:23 date\n",
      "В республике издадут туристический путеводитель по лучшим гастрономическим местам республики. short_title\n",
      "В Уфе разрабатывается кофейный напиток «уфачино» title\n",
      "28.12.2023 10:59 date\n",
      "Его будут готовить из кофейных зерен, которые растут на деревьях в уфимском лимонарии. short_title\n",
      "Фестиваль «Есть» в Уфе стал победителем премии в сфере событийного туризма title\n",
      "25.11.2023 17:30 date\n",
      "Фестиваль объединил 140 участников и более 150 тысяч гостей. short_title\n",
      "Повара из Уфы участвуют в кастинге шоу «Битва шефов» Ивлева и Агзамова title\n",
      "13.11.2023 10:39 date\n",
      "Мастера из столицы Башкирии предложили татарский пирог «Губадия» и кролика в апельсиновой глазури. short_title\n",
      "Башкирия начнет поставлять в Китай куриные лапки в обмен на утиные грудки title\n",
      "09.11.2023 14:11 date\n",
      "Республика планирует отгружать в Китай по 700 тонн товара в месяц. short_title\n",
      "Башкирия будет поставлять в Китай мороженое title\n",
      "07.11.2023 20:33 date\n",
      "Всего во время бизнес-миссии, которая находится сейчас в Шанхае, бизнесмены республики провели более 100 встреч и подписали 19 соглашений. short_title\n",
      "«Гастрономика» - первый фуд-молл Уфы в «Гостином дворе» откроется в ноябре title\n",
      "03.11.2023 16:25 date\n",
      "Формат фуд-моллов и фуд-маркетов не первый год остается в модных трендах по всему миру. Не стала исключением и Уфа, в ноябре в «Гостином дворе» открывается фуд-молл «Гастрономика». short_title\n",
      "Башкирский кыстыбый. Раскрываем секрет национального блюда title\n",
      "29.09.2023 08:00 date\n",
      "Он поделится с гостями и жителями Уфы авторским рецептом вкусного завтрака, используя местные продукты. short_title\n",
      "В Башкирии испекли самое большое пирожное «Муравейник» в России title\n",
      "27.08.2023 23:48 date\n",
      "Огромный дессерт приготовили в честь 60-летия Нефтекамска. short_title\n",
      "В Башкирии приготовили огромный бэлеш весом 140 кг title\n",
      "25.08.2023 18:11 date\n",
      "Блюдо стало кульминацией праздника «Бэлешфест» в Буздякском районе. short_title\n",
      "Уфимская компания засудила казанскую предпринимательницу на 300 тыс. рублей title\n",
      "25.08.2023 16:43 date\n",
      "Женщина заказала товар на 295 тыс. рублей и, отказавшись платить, закрыла ИП. short_title\n",
      "В меню школьного питания в Башкирии включили чипсы, митболы и наггетсы title\n",
      "23.08.2023 08:04 date\n",
      "Для школьного питания разработано 2 вида меню - базовое и по сборнику рецептур Г.Г. Онищенко и В.А. Тутельян. short_title\n",
      "Ресторан Башкирии на ПМЭФ с кониной за 5 тыс. посетило 1,5 тыс. человек title\n",
      "19.06.2023 12:35 date\n",
      "Национальная кухня пользовалась популярностью о гостей форума. short_title\n",
      "В Уфе приготовили самые большие учпочмак и кыстыбый title\n",
      "12.06.2023 13:32 date\n",
      "Национальные блюда по своим размерам претендуют на рекорд  России. short_title\n",
      "Диетолог Сахайя назвала еду и напитки, которые не стоит употреблять утром title\n",
      "29.05.2023 17:51 date\n",
      "Некоторые любимые блюда могу принести вред организму. short_title\n",
      "За последний год жители ПФО стали есть меньше говядины и больше мяса птицы title\n",
      "21.03.2023 09:19 date\n",
      "В целом жители округа любят мясо больше, чем рыбу. short_title\n",
      "В Уфе 15 января выберут «Лучший рождественский стол» title\n",
      "14.01.2023 19:40 date\n",
      "Конкурс организуют в торговом комплексе «Гостиный двор». short_title\n",
      "Кухня региона. Вкусно и целебно в Башкирии title\n",
      "28.06.2022 17:33 date\n",
      "Все в республике знают и любят национальные блюда. short_title\n",
      "Медовые, кокосовые, банановые. Самые вкусные блины на Масленицу title\n",
      "25.02.2022 19:10 date\n",
      "Подборку рецептов подготовил UFA.AIF.RU. short_title\n",
      "Сила в простоте. Кулинарный эксперт – о замесе дрожжевого теста title\n",
      "22.02.2022 17:45 date\n",
      "Специалист в области производства продуктов питания раскрыл все секреты приготовления вкусной выпечки. short_title\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for node, label in zip(valid_data[idx]['nodes'][0], valid_data[idx]['node_labels'][0]):\n",
    "  if id2label[label] != 'OTHER':\n",
    "    print(node, id2label[label])\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Инициалиация датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkupLMDataset(Dataset):\n",
    "    \"\"\"Dataset for token classification with MarkupLM.\"\"\"\n",
    "\n",
    "    def __init__(self, data, processor=None):\n",
    "        self.data = data\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # first, get nodes, xpaths and node labels\n",
    "        item = self.data[idx]\n",
    "        nodes, xpaths, node_labels = item['nodes'], item['xpaths'], item['node_labels']\n",
    "\n",
    "        # provide to processor\n",
    "        encoding = self.processor(nodes=nodes, xpaths=xpaths, node_labels=node_labels, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "        # remove batch dimension\n",
    "        encoding = {k: v.squeeze() for k, v in encoding.items()}\n",
    "\n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = MarkupLMProcessor.from_pretrained(\"microsoft/markuplm-base\", truncation = True)\n",
    "processor.parse_html = False\n",
    "\n",
    "train_set = MarkupLMDataset(data=train_data, processor=processor)\n",
    "valid_set = MarkupLMDataset(data=valid_data, processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([512])\n",
      "token_type_ids torch.Size([512])\n",
      "attention_mask torch.Size([512])\n",
      "xpath_tags_seq torch.Size([512, 50])\n",
      "xpath_subs_seq torch.Size([512, 50])\n",
      "labels torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "example = valid_set[0]\n",
    "for k,v in example.items():\n",
    "  print(k,v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>created_at 25-02-2024 19:51:43window.isIndexPage = 0;\\n        window.isMobileBrowser = 0;\\n        window.disableSidebarCut = 1;\\n        window.bannerDebugMode = 0;Еда и продукты на | АиФ-Уфа[if IE 8]><link href=\"https://ufa.aif.ru/css/ie8.css?44f\" media=\"all\" rel=\"stylesheet\" type=\"text/css\" ><![endif][if lt IE 10]><link href=\"https://ufa.aif.ru/css/ie9.css?44f\" media=\"all\" rel=\"stylesheet\" type=\"text/css\" ><![endif]//<!--\\n    var isRedesignPage = false;    //-->[if lt IE 9]><script type=\"text/javascript\" src=\"https://html5shiv.googlecode.com/svn/trunk/html5.js?44f\"></script><![endif][if lt IE 10]><script type=\"text/javascript\" src=\"https://ufa.aif.ru/resources/front/js/hybrid/css3-multi-column.js?44f\"></script><![endif]//<!--\\n    var _sf_startpt=(new Date()).getTime()    //-->//<!--\\n    function AdFox_getWindowSize() {\\n    var winWidth,winHeight;\\n\\tif( typeof( window.innerWidth ) == \\'number\\' ) {\\n\\t\\t//Non-IE\\n\\t\\twinWidth = window.innerWidth;\\n\\t\\twinHeight = window.innerHeight;\\n\\t} else if( document.documentElement && ( document.documentElement.clientWidth || document.documentElement.clientHeight ) ) {\\n\\t\\t//IE 6+ in\\'standards compliant mode\\'\\n\\t\\twinWidth = document.documentElement.clientWidth;\\n\\t\\twinHeight = document.documentElement.clientHeight;\\n\\t} else if( document.body && ( document</s>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.decode(example['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id, label in zip(example['input_ids'].tolist(), example['labels'].tolist()):\n",
    "    # if label != -100:\n",
    "    #     print(processor.decode([id]), label)\n",
    "    if label == 1:\n",
    "        print(processor.decode([id]), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_set, batch_size=3, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_set, batch_size=3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MarkupLMForTokenClassification were not initialized from the model checkpoint at microsoft/markuplm-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = MarkupLMForTokenClassification.from_pretrained(\"microsoft/markuplm-base\", id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [\"B-\" + x for x in list(id2label.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "# Metric\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "def get_labels(predictions, references):\n",
    "    # Transform predictions and references tensos to numpy arrays\n",
    "    if device.type == \"cpu\":\n",
    "        y_pred = predictions.detach().clone().numpy()\n",
    "        y_true = references.detach().clone().numpy()\n",
    "    else:\n",
    "        y_pred = predictions.detach().cpu().clone().numpy()\n",
    "        y_true = references.detach().cpu().clone().numpy()\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(pred, gold_label) if l != -100]\n",
    "        for pred, gold_label in zip(y_pred, y_true)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(pred, gold_label) if l != -100]\n",
    "        for pred, gold_label in zip(y_pred, y_true)\n",
    "    ]\n",
    "    return true_predictions, true_labels\n",
    "\n",
    "def compute_metrics(metric, return_entity_level_metrics=True):\n",
    "    results = metric.compute()\n",
    "    if return_entity_level_metrics:\n",
    "        # Unpack nested dictionaries\n",
    "        final_results = {}\n",
    "        for key, value in results.items():\n",
    "            if isinstance(value, dict):\n",
    "                for n, v in value.items():\n",
    "                    final_results[f\"{key}_{n}\"] = v\n",
    "            else:\n",
    "                final_results[key] = value\n",
    "        return final_results\n",
    "    else:\n",
    "        return {\n",
    "            \"precision\": results[\"overall_precision\"],\n",
    "            \"recall\": results[\"overall_recall\"],\n",
    "            \"f1\": results[\"overall_f1\"],\n",
    "            \"accuracy\": results[\"overall_accuracy\"],\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 660/660 [07:35<00:00,  1.45it/s]\n",
      "/home/ubuntu/.cache/pypoetry/virtualenvs/markupclassification-_GlTHi5g-py3.9/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ubuntu/.cache/pypoetry/virtualenvs/markupclassification-_GlTHi5g-py3.9/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: {'author_precision': 0.0, 'author_recall': 0.0, 'author_f1': 0.0, 'author_number': 0, 'date_precision': 0.0, 'date_recall': 0.0, 'date_f1': 0.0, 'date_number': 0, 'short_text_precision': 0.0, 'short_text_recall': 0.0, 'short_text_f1': 0.0, 'short_text_number': 40, 'short_title_precision': 0.06666666666666667, 'short_title_recall': 0.05714285714285714, 'short_title_f1': 0.061538461538461535, 'short_title_number': 70, 'time_precision': 0.0, 'time_recall': 0.0, 'time_f1': 0.0, 'time_number': 16, 'title_precision': 0.9945244956772334, 'title_recall': 0.9941425004801229, 'title_f1': 0.994333461390703, 'title_number': 20828, 'overall_precision': 0.988355445261048, 'overall_recall': 0.988355445261048, 'overall_f1': 0.988355445261048, 'overall_accuracy': 0.988355445261048}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 660/660 [07:56<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: {'short_text_precision': 0.0, 'short_text_recall': 0.0, 'short_text_f1': 0.0, 'short_text_number': 40, 'short_title_precision': 0.0, 'short_title_recall': 0.0, 'short_title_f1': 0.0, 'short_title_number': 70, 'time_precision': 0.0, 'time_recall': 0.0, 'time_f1': 0.0, 'time_number': 16, 'title_precision': 0.9939868282905412, 'title_recall': 1.0, 'title_f1': 0.9969843473266, 'title_number': 20828, 'overall_precision': 0.9939868282905412, 'overall_recall': 0.9939868282905412, 'overall_f1': 0.9939868282905412, 'overall_accuracy': 0.9939868282905412}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 143/660 [01:43<07:49,  1.10it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "model.train()\n",
    "print(device)\n",
    "for epoch in range(10):\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        # get the inputs;\n",
    "        inputs = {k:v.to(device) for k,v in batch.items()}\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print(\"Loss:\", loss.item())\n",
    "\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        labels = batch[\"labels\"]\n",
    "        preds, refs = get_labels(predictions, labels)\n",
    "        metric.add_batch(\n",
    "            predictions=preds,\n",
    "            references=refs,\n",
    "        )\n",
    "\n",
    "    train_metric = compute_metrics(metric)\n",
    "    print(f\"Epoch {epoch}:\", train_metric)\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "print(device)\n",
    "\n",
    "test_metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "for batch in tqdm(valid_dataloader):\n",
    "    # get the inputs;\n",
    "    inputs = {k:v.to(device) for k,v in batch.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    predictions = outputs.logits.argmax(dim=-1)\n",
    "    labels = batch[\"labels\"]\n",
    "    preds, refs = get_labels(predictions, labels)\n",
    "    test_metric.add_batch(\n",
    "        predictions=preds,\n",
    "        references=refs,\n",
    "    )\n",
    "\n",
    "eval_metric = compute_metrics(test_metric)\n",
    "print(\"TESTING RESULT :\", eval_metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "markup-segmentation-03k7_eFX-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
